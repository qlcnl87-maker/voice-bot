import subprocess
import sys
import os

# [ìˆ˜ì •] ì¬ìƒ ë²„íŠ¼ í´ë¦­ ì‹œ streamlit run ëª…ë ¹ì–´ë¡œ ìë™ ì „í™˜í•´ì£¼ëŠ” ë¡œì§
if __name__ == "__main__":
    if not hasattr(sys, '_streamlit_run_script') and os.environ.get("STREAMLIT_ALREADY_RUNNING") != "true":
        os.environ["STREAMLIT_ALREADY_RUNNING"] = "true"
        # í˜„ì¬ íŒŒì¼ì„ streamlit runìœ¼ë¡œ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        subprocess.run([sys.executable, "-m", "streamlit", "run", sys.argv[0]])
        sys.exit()

# ---------------------------------------------------------
# ì•„ë˜ë¶€í„°ëŠ” ìŠ¤íŠ¸ë¦¼ë¦¿ ë³¸ ì½”ë“œì…ë‹ˆë‹¤.
# ---------------------------------------------------------
import streamlit as st
from streamlit_mic_recorder import mic_recorder
import google.generativeai as genai
from gtts import gTTS
import tempfile
from datetime import datetime
import base64


# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸ (ìµœìƒë‹¨)
st.set_page_config(page_title="ì œë¯¸ë‚˜ì´ ìŒì„± ë¹„ì„œ", page_icon="ğŸ™ï¸", layout="wide")

st.markdown("""
    <style>
    /* ì „ì²´ ë°°ê²½ìƒ‰ */
    .main { background-color: #f8f9fa; }
    
    /* ëª¨ë“  ë²„íŠ¼ì„ íŒŒë€ìƒ‰ìœ¼ë¡œ ê³ ì • ë° ë¹¨ê°„ í…Œë‘ë¦¬ ì œê±° */
    div.stButton > button, div.stForm submit_button > button {
        background-color: #007bff !important;
        color: white !important;
        border: 1px solid #007bff !important;
        width: 100% !important;
        height: 3.5em !important;
        border-radius: 10px !important;
        font-weight: bold !important;
        box-shadow: none !important;
    }
    
    /* ì…ë ¥ì°½ í¬ì»¤ìŠ¤ ì‹œ íŒŒë€ìƒ‰ í…Œë‘ë¦¬ */
    .stTextInput > div > div > input:focus {
        border-color: #007bff !important;
    }

    /* ë³¼ë¥¨ ë¹„ì£¼ì–¼ë¼ì´ì € ë°•ìŠ¤ */
    .vol-container {
        display: flex; justify-content: center; align-items: center; height: 50px;
        background: #f0f7ff; border-radius: 8px; margin-bottom: 10px; border: 1px solid #cce5ff;
    }
    .vol-bar {
        width: 4px; height: 12px; background: #007bff; margin: 0 2px; border-radius: 5px;
        animation: wave 1s infinite ease-in-out;
    }
    @keyframes wave { 0%, 100% { height: 10px; opacity: 0.5; } 50% { height: 30px; opacity: 1; } }

    /* í…ìŠ¤íŠ¸ ì§ˆë¬¸ ë°•ìŠ¤ ë‚´ë¶€ ì—¬ë°± ìµœì í™” */
    [data-testid="stForm"] { padding: 0px !important; border: none !important; }
    </style>
""", unsafe_allow_html=True)

# 2. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
if 'history' not in st.session_state: st.session_state.history = []
if 'api_key' not in st.session_state: st.session_state.api_key = ''
if 'last_processed_id' not in st.session_state: st.session_state.last_processed_id = None
if 'api_valid' not in st.session_state: st.session_state.api_valid = None

# 3. í•µì‹¬ ë¡œì§ í•¨ìˆ˜
def validate_api_key(api_key):
    try:
        genai.configure(api_key=api_key)
        genai.list_models()
        return True
    except: return False

def get_chat_response(api_key, text_input):
    """AI ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” í•µì‹¬ í•¨ìˆ˜"""
    try:
        genai.configure(api_key=api_key)
        # í˜„ì¬ ì‹œê°„(2026ë…„) ì •ë³´ë¥¼ ì£¼ì…í•˜ì—¬ ë‹µë³€ ì •í™•ë„ í–¥ìƒ
        now_info = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ")
        enriched_prompt = f"í˜„ì¬ ì‹œê°ì€ {now_info}ì…ë‹ˆë‹¤. ì´ ì‹œì ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {text_input}"
        
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(enriched_prompt)
        return response.text
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}"

def process_voice_to_text(api_key, audio_bytes):
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT)"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content([
            {"mime_type": "audio/webm", "data": audio_bytes}, 
            "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œë§Œ ì •í™•íˆ ë°›ì•„ì“°ê¸°í•´ì¤˜."
        ])
        return response.text.strip()
    except Exception as e:
        return f"ì¸ì‹ ì‹¤íŒ¨: {str(e)}"

def text_to_speech(text):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (TTS)"""
    try:
        clean_text = text.replace('*', '').replace('#', '')[:300]
        tts = gTTS(text=clean_text, lang='ko')
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
            tts.save(fp.name)
            return fp.name
    except: return None

def autoplay_audio(file_path):
    """ìŒì„± ìë™ ì¬ìƒ"""
    with open(file_path, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        st.markdown(f'<audio autoplay="true"><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio>', unsafe_allow_html=True)
    os.remove(file_path)

# 4. í™”ë©´ ë ˆì´ì•„ì›ƒ
st.markdown("<h1 style='text-align: center; color: #007bff;'>ğŸ™ï¸ ì œë¯¸ë‚˜ì´ ìŒì„± ë¹„ì„œ</h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    input_key = st.text_input("Gemini API í‚¤ ì…ë ¥", type="password", value=st.session_state.api_key)
    
    if input_key and input_key != st.session_state.api_key:
        st.session_state.api_key = input_key
        st.session_state.api_valid = validate_api_key(input_key)
    
    if st.session_state.api_valid:
        st.success("âœ… API ì—°ê²°ë¨ (Gemini 2.0)")
    elif st.session_state.api_key:
        st.error("âŒ ì˜ëª»ëœ API í‚¤")
        
    enable_tts = st.checkbox("ğŸ”Š ìŒì„± ì¶œë ¥(TTS) í™œì„±í™”", value=True)
    st.markdown("---")

    # í”„ë¡œê·¸ë¨ ì •ë³´ ì„¹ì…˜ ë³µêµ¬
    with st.expander("â„¹ï¸ í”„ë¡œê·¸ë¨ ì •ë³´", expanded=True):
        st.write("**â€¢ STT:** ì œë¯¸ë‚˜ì´ ê²©ë¦¬ ì¸ì‹")
        st.write("**â€¢ ë‹µë³€:** Google Gemini AI (ê²€ìƒ‰ ì§€ì›)")
        st.write("**â€¢ TTS:** êµ¬ê¸€ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜")
        st.write("**â€¢ API:** Google AI SDK ì‚¬ìš©")    
    
    
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.history = []; st.session_state.last_processed_id = None; st.rerun()

# 5. ë©”ì¸ ì¸í„°ë™í‹°ë¸Œ ì„¹ì…˜
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ¤ ìŒì„± ì§ˆë¬¸")
    with st.container(border=True):
        # ë³¼ë¥¨ ë¹„ì£¼ì–¼ë¼ì´ì €
        st.markdown('<div class="vol-container"><div class="vol-bar" style="animation-delay:0s"></div><div class="vol-bar" style="animation-delay:0.2s"></div><div class="vol-bar" style="animation-delay:0.4s"></div><div class="vol-bar" style="animation-delay:0.2s"></div><div class="vol-bar" style="animation-delay:0s"></div></div>', unsafe_allow_html=True)
        
        if st.session_state.api_valid:
            audio = mic_recorder(start_prompt="ğŸ”µ ëŒ€í™” ì‹œì‘", stop_prompt="ğŸ›‘ ë¶„ì„ ìš”ì²­", key='recorder', use_container_width=True)
            if audio:
                if audio.get('id') != st.session_state.last_processed_id:
                    st.session_state.last_processed_id = audio.get('id')
                    with st.spinner("ğŸ§ ë¶„ì„ ì¤‘..."):
                        user_text = process_voice_to_text(st.session_state.api_key, audio['bytes'])
                        ai_a = get_chat_response(st.session_state.api_key, user_text)
                        st.session_state.history.append({"q": f"ğŸ™ï¸ {user_text}", "a": ai_a, "time": datetime.now().strftime("%H:%M:%S")})
                        if enable_tts:
                            path = text_to_speech(ai_a)
                            if path: autoplay_audio(path)
                    st.rerun()
        else:
            st.info("API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.")

with col2:
    st.subheader("âŒ¨ï¸ í…ìŠ¤íŠ¸ ì§ˆë¬¸")
    with st.container(border=True):
        # ìƒë‹¨ ê³µë°± ìµœì í™”
        st.markdown('<div style="height:15px;"></div>', unsafe_allow_html=True)
        with st.form(key='text_input_form', clear_on_submit=True):
            t_input = st.text_input(label="ì§ˆë¬¸ ë‚´ìš©", placeholder="ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”.", label_visibility="collapsed")
            submit_button = st.form_submit_button(label='ğŸ“¤ ì§ˆë¬¸ ì „ì†¡', use_container_width=True)
            
            if submit_button and t_input and st.session_state.api_valid:
                with st.spinner("ğŸ¤” ìƒê° ì¤‘..."):
                    ai_a = get_chat_response(st.session_state.api_key, t_input)
                    st.session_state.history.append({"q": t_input, "a": ai_a, "time": datetime.now().strftime("%H:%M:%S")})
                    if enable_tts:
                        path = text_to_speech(ai_a)
                        if path: autoplay_audio(path)
                st.rerun()

# 6. ì±„íŒ… ì´ë ¥ í‘œì‹œ
st.markdown("---")
if st.session_state.history:
    for item in reversed(st.session_state.history):
        st.markdown(f"""
        <div style="border: 1px solid #e0e6ed; padding: 15px; border-radius: 10px; margin-bottom: 10px; background-color: #ffffff;">
            <div style="color: #888; font-size: 0.8rem; margin-bottom: 5px;">[{item['time']}]</div>
            <div style="font-weight: bold; color: #007bff;">Q: {item['q']}</div>
            <div style="margin-top: 5px;"><b>A:</b> {item['a']}</div>
        </div>

        """, unsafe_allow_html=True)
