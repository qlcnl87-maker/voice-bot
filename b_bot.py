import subprocess
import sys
import os

# 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜ ë° ì´ˆê¸°í™”
def initialize_app():
    packages = ["streamlit", "streamlit-mic-recorder", "google-generativeai", "gTTS"]
    for package in packages:
        try:
            import_name = package.replace("-", "_").lower()
            __import__(import_name)
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

    if not hasattr(sys, '_streamlit_run_script') and os.environ.get("STREAMLIT_ALREADY_RUNNING") != "true":
        os.environ["STREAMLIT_ALREADY_RUNNING"] = "true"
        subprocess.run([sys.executable, "-m", "streamlit", "run", sys.argv[0]])
        sys.exit()

initialize_app()

# ---------------------------------------------------------
# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ---------------------------------------------------------
import streamlit as st
import streamlit.components.v1 as components
from streamlit_mic_recorder import mic_recorder
import google.generativeai as genai
from gtts import gTTS
import tempfile
from datetime import datetime
import base64

# ---------------------------------------------------------
# 3. ë””ìì¸ ë° ê°€ë…ì„± ì„¤ì • (CSS)
# ---------------------------------------------------------
st.set_page_config(page_title="ì œë¯¸ë‚˜ì´ ìŒì„± ë¹„ì„œ", page_icon="ğŸ™ï¸", layout="wide")

st.markdown("""
<style>
    .main { background-color: #f0f2f6; }
    .stButton>button { 
        width: 100%; border-radius: 12px; font-weight: bold; height: 50px; 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; 
    }
    .chat-bubble { 
        background: white; border-radius: 18px; padding: 25px; margin-bottom: 20px; 
        box-shadow: 0 4px 12px rgba(0,0,0,0.05); border-left: 8px solid #667eea;
    }
    .user-q { font-size: 1.1rem; font-weight: 600; color: #333; margin-bottom: 10px; }
    .ai-a { font-size: 1.25rem; line-height: 1.6; color: #2c3e50; }
    .api-status { font-size: 0.9rem; font-weight: bold; margin-top: 5px; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 4. ì‹¤ì‹œê°„ ë§ˆì´í¬ ë³¼ë¥¨ ë¹„ì£¼ì–¼ë¼ì´ì € (ì¶•ì†Œí˜• ë³µêµ¬)
# ---------------------------------------------------------
def audio_visualizer():
    visualizer_html = """
    <div style="background: #1e1e1e; padding: 5px; border-radius: 10px; border: 1px solid #333; margin-bottom: 10px;">
        <div style="color: #4CAF50; font-size: 10px; font-family: sans-serif; margin-bottom: 3px; text-align: center; font-weight: bold;">AUDIO INPUT ACTIVE</div>
        <canvas id="canvas" style="width: 100%; height: 25px;"></canvas>
    </div>
    <script>
    async function startVisualizer() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            analyser.fftSize = 64;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            function draw() {
                requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                const barWidth = (canvas.width / bufferLength) * 2;
                let x = 0;
                for(let i = 0; i < bufferLength; i++) {
                    let barHeight = dataArray[i] / 5;
                    ctx.fillStyle = `rgb(102, 126, ${dataArray[i]+150})`;
                    ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 2;
                }
            }
            draw();
        } catch (err) { console.error("Mic error:", err); }
    }
    startVisualizer();
    </script>
    """
    components.html(visualizer_html, height=65)

# ---------------------------------------------------------
# 5. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
# ---------------------------------------------------------
if 'history' not in st.session_state: st.session_state.history = []
if 'api_key' not in st.session_state: st.session_state.api_key = ''
if 'last_processed_id' not in st.session_state: st.session_state.last_processed_id = None
if 'api_valid' not in st.session_state: st.session_state.api_valid = None

# ---------------------------------------------------------
# 6. í•µì‹¬ ì²˜ë¦¬ ë¡œì§ (ì˜¤ë¥˜ í•´ê²° ë° ê²€ìƒ‰ ì§€ì›)
# ---------------------------------------------------------
def validate_api_key(api_key):
    try:
        genai.configure(api_key=api_key)
        genai.list_models()
        return True
    except:
        return False

def get_chat_response(api_key, text_input):
    try:
        genai.configure(api_key=api_key)
        # 400 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ë™ì ì¸ ë„êµ¬ í• ë‹¹ ì‹œë„
        try:
            model = genai.GenerativeModel(model_name="gemini-2.0-flash-exp", tools=[{"google_search": {}}])
            response = model.generate_content(text_input)
        except:
            model = genai.GenerativeModel("gemini-2.0-flash-exp")
            response = model.generate_content(text_input)
        return response.text
    except Exception as e:
        return f"âš ï¸ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}"

def process_voice_to_text(api_key, audio_bytes):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-2.0-flash-exp")
        response = model.generate_content([{"mime_type": "audio/webm", "data": audio_bytes}, "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œë§Œ ë°›ì•„ì“°ê¸°í•´ì¤˜."])
        return response.text.strip()
    except Exception as e:
        return f"ì¸ì‹ ì‹¤íŒ¨: {str(e)}"

def text_to_speech(text):
    try:
        clean_text = text.replace('*', '').replace('#', '')[:300]
        tts = gTTS(text=clean_text, lang='ko')
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
            tts.save(fp.name)
            return fp.name
    except: return None

def autoplay_audio(file_path):
    with open(file_path, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        st.markdown(f'<audio autoplay="true"><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio>', unsafe_allow_html=True)
    os.remove(file_path)

# ---------------------------------------------------------
# 7. UI ë ˆì´ì•„ì›ƒ
# ---------------------------------------------------------
st.markdown("<h1 style='text-align: center; color: #4A90E2;'>ğŸ™ï¸ ì œë¯¸ë‚˜ì´ ìŒì„± ë¹„ì„œ</h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    input_key = st.text_input("Gemini API í‚¤ ì…ë ¥", type="password", value=st.session_state.api_key)
    
    if input_key and input_key != st.session_state.api_key:
        st.session_state.api_key = input_key
        st.session_state.api_valid = validate_api_key(input_key)
    
    # [ë³µêµ¬] API ì—°ê²° ì •ë³´ í‘œì‹œ
    if st.session_state.api_key:
        if st.session_state.api_valid:
            st.markdown('<p style="color: #28a745;" class="api-status">âœ… API ì—°ê²°ë¨ (Gemini 2.0 Ready)</p>', unsafe_allow_html=True)
        else:
            st.markdown('<p style="color: #dc3545;" class="api-status">âŒ ì˜ëª»ëœ API í‚¤</p>', unsafe_allow_html=True)
            
    enable_tts = st.checkbox("ğŸ”Š ìŒì„± ì¶œë ¥(TTS) í™œì„±í™”", value=True)
    st.markdown("---")
    
    # [ë³µêµ¬] í”„ë¡œê·¸ë¨ ì •ë³´ (ì¤„ë°”ê¿ˆ ì •ë ¬)
    with st.expander("â„¹ï¸ í”„ë¡œê·¸ë¨ ì •ë³´", expanded=True):
        st.write("**â€¢ STT:** ì œë¯¸ë‚˜ì´ ê²©ë¦¬ ì¸ì‹")
        st.write("**â€¢ ë‹µë³€:** Google Gemini AI (ê²€ìƒ‰ ì§€ì›)")
        st.write("**â€¢ TTS:** êµ¬ê¸€ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜")
        st.write("**â€¢ API:** Google AI SDK ì‚¬ìš©")
    
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.history = []; st.session_state.last_processed_id = None; st.rerun()

# ---------------------------------------------------------
# 8. ë©”ì¸ ì¸í„°ë™í‹°ë¸Œ ì„¹ì…˜   ---             
# ---------------------------------------------------------

import streamlit as st
from datetime import datetime


# 1. ìŠ¤íƒ€ì¼ ì„¤ì • (ê³µë°± ìµœì†Œí™” ë° íŒŒë€ìƒ‰ í…Œë§ˆ)
st.markdown("""
    <style>
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ (íŒŒë€ìƒ‰) */
    div.stButton > button, 
    div.stForm submit_button > button {
        background-color: #007bff !important;
        color: white !important;
        border: 1px solid #007bff !important;
        width: 100% !important;
        height: 3em !important;
        border-radius: 8px !important;
        font-weight: bold !important;
    }
    
    /* ë³¼ë¥¨ ë¹„ì£¼ì–¼ë¼ì´ì € (ë†’ì´ ì‚´ì§ ì¡°ì ˆ) */
    .vol-container {
        display: flex;
        justify-content: center;
        align-items: center;
        height: 50px;
        background: #f0f7ff;
        border-radius: 8px;
        margin-bottom: 10px;
        border: 1px solid #cce5ff;
    }
    .vol-bar {
        width: 4px; height: 12px; background: #007bff;
        margin: 0 2px; border-radius: 5px;
        animation: wave 1s infinite ease-in-out;
    }
    @keyframes wave { 0%, 100% { height: 10px; opacity: 0.5; } 50% { height: 30px; opacity: 1; } }

    /* í¼ ë‚´ë¶€ ì—¬ë°± ì¤„ì´ê¸° */
    [data-testid="stForm"] {
        padding: 0px !important;
        border: none !important;
    }
    </style>
""", unsafe_allow_html=True)

# 2. ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def ask_ai_with_time(api_key, user_input):
    now_info = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ")
    enriched_prompt = f"í˜„ì¬ ì‹œê°ì€ {now_info}ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {user_input}"
    return get_chat_response(api_key, enriched_prompt)

col1, col2 = st.columns(2)

# --- ğŸ¤ ìŒì„± ì§ˆë¬¸ ì„¹ì…˜ (ì™¼ìª½) ---
with col1:
    st.subheader("ğŸ¤ ìŒì„± ì§ˆë¬¸")
    with st.container(border=True):
        st.markdown('<div class="vol-container"><div class="vol-bar" style="animation-delay:0s"></div><div class="vol-bar" style="animation-delay:0.2s"></div><div class="vol-bar" style="animation-delay:0.4s"></div><div class="vol-bar" style="animation-delay:0.2s"></div><div class="vol-bar" style="animation-delay:0s"></div></div>', unsafe_allow_html=True)
        
        if st.session_state.get('api_valid', False):
            audio = mic_recorder(start_prompt="ğŸ”µ ëŒ€í™” ì‹œì‘", stop_prompt="ğŸ›‘ ë¶„ì„ ìš”ì²­", key='recorder', use_container_width=True)
            if audio:
                current_id = audio.get('id')
                if current_id != st.session_state.get('last_processed_id'):
                    st.session_state.last_processed_id = current_id
                    with st.spinner("ğŸ§ ë¶„ì„ ì¤‘..."):
                        user_text = process_voice_to_text(st.session_state.api_key, audio['bytes'])
                        ai_a = ask_ai_with_time(st.session_state.api_key, user_text)
                        st.session_state.history.append({"q": f"ğŸ™ï¸ {user_text}", "a": ai_a, "time": datetime.now().strftime("%H:%M:%S")})
                    st.rerun()
        else:
            st.info("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# --- âŒ¨ï¸ í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì„¹ì…˜ (ì˜¤ë¥¸ìª½) ---
with col2:
    st.subheader("âŒ¨ï¸ í…ìŠ¤íŠ¸ ì§ˆë¬¸")
    with st.container(border=True):
        # ìƒë‹¨ ê³µë°±ì„ 70pxì—ì„œ 15pxë¡œ ì¤„ì—¬ì„œ ìœ„ë¡œ ë°”ì§ ë¶™ì„
        st.markdown('<div style="height:15px;"></div>', unsafe_allow_html=True)
        
        with st.form(key='text_input_form', clear_on_submit=True):
            t_input = st.text_input(label="ì§ˆë¬¸ ë‚´ìš©", placeholder="ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”.", label_visibility="collapsed")
            submit_button = st.form_submit_button(label='ğŸ“¤ ì§ˆë¬¸ ì „ì†¡', use_container_width=True)
            
            if submit_button and t_input and st.session_state.get('api_valid', False):
                with st.spinner("ğŸ¤” ìƒê° ì¤‘..."):
                    ai_a = ask_ai_with_time(st.session_state.api_key, t_input)
                    st.session_state.history.append({"q": t_input, "a": ai_a, "time": datetime.now().strftime("%H:%M:%S")})
                st.rerun()

# --- ì±„íŒ… ì´ë ¥ ì¶œë ¥ ---
st.markdown("---")
if st.session_state.get('history'):
    for item in reversed(st.session_state.history):
        st.markdown(f"""
        <div style="border: 1px solid #e0e6ed; padding: 15px; border-radius: 10px; margin-bottom: 10px; background-color: #f8f9fa;">
            <div style="color: #888; font-size: 0.8rem; margin-bottom: 5px;">[{item['time']}]</div>
            <div style="font-weight: bold; color: #007bff;">Q: {item['q']}</div>
            <div style="margin-top: 5px;"><b>A:</b> {item['a']}</div>
        </div>
        """, unsafe_allow_html=True)